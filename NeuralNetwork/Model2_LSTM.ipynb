{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM_model2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM_model2 uses 2 layers of LSTM with N=100 times steps, Nh=150 hidden units.\n",
    "Dataset can be downloaded in http://www.montefiore.ulg.ac.be/services/acous/STSI/downloads.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 1.13.1 of tensorflow\n",
      "maxSize = 6726407\n",
      "shape input train (6726308, 100)\n",
      "Data loaded\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py:694: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -0 calculated in 535.19 s \n",
      "Epoch 0, NRMSE Test/best: 0.78098/0.78098, Training NRMSE: 0.57523, deviation of 35.77%\n",
      "Epoch -1 calculated in 546.75 s \n",
      "Epoch 1, NRMSE Test/best: 0.57585/0.57585, Training NRMSE: 0.42671, deviation of 34.95%\n",
      "Epoch -2 calculated in 547.76 s \n",
      "Epoch 2, NRMSE Test/best: 0.63835/0.57585, Training NRMSE: 0.39978, deviation of 59.68%\n",
      "Epoch -3 calculated in 549.07 s \n",
      "Epoch 3, NRMSE Test/best: 0.68904/0.57585, Training NRMSE: 0.38832, deviation of 77.44%\n",
      "Epoch -4 calculated in 548.45 s \n",
      "Epoch 4, NRMSE Test/best: 0.62278/0.57585, Training NRMSE: 0.38151, deviation of 63.24%\n",
      "Epoch -5 calculated in 546.20 s \n",
      "Epoch 5, NRMSE Test/best: 0.59506/0.57585, Training NRMSE: 0.37682, deviation of 57.92%\n",
      "Epoch -6 calculated in 547.41 s \n",
      "Epoch 6, NRMSE Test/best: 0.65284/0.57585, Training NRMSE: 0.37349, deviation of 74.79%\n",
      "Epoch -7 calculated in 546.34 s \n",
      "Epoch 7, NRMSE Test/best: 0.60479/0.57585, Training NRMSE: 0.37148, deviation of 62.81%\n",
      "Epoch -8 calculated in 546.46 s \n",
      "Epoch 8, NRMSE Test/best: 0.71825/0.57585, Training NRMSE: 0.37207, deviation of 93.04%\n",
      "Epoch -9 calculated in 546.23 s \n",
      "Epoch 9, NRMSE Test/best: 1.08110/0.57585, Training NRMSE: 0.46084, deviation of 134.59%\n",
      "Epoch -10 calculated in 545.86 s \n",
      "Epoch 10, NRMSE Test/best: 1.33511/0.57585, Training NRMSE: 1.01576, deviation of 31.44%\n",
      "Epoch -11 calculated in 546.51 s \n",
      "Epoch 11, NRMSE Test/best: 1.19844/0.57585, Training NRMSE: 0.96491, deviation of 24.20%\n",
      "Epoch -12 calculated in 547.61 s \n",
      "Epoch 12, NRMSE Test/best: 1.18283/0.57585, Training NRMSE: 0.96464, deviation of 22.62%\n",
      "Epoch -13 calculated in 546.78 s \n",
      "Epoch 13, NRMSE Test/best: 2.48892/0.57585, Training NRMSE: 0.89641, deviation of 177.66%\n",
      "Epoch -14 calculated in 547.25 s \n",
      "Epoch 14, NRMSE Test/best: 1.30551/0.57585, Training NRMSE: 0.91218, deviation of 43.12%\n",
      "Epoch -15 calculated in 546.99 s \n",
      "Epoch 15, NRMSE Test/best: 0.91580/0.57585, Training NRMSE: 0.77760, deviation of 17.77%\n",
      "Epoch -16 calculated in 545.96 s \n",
      "Epoch 16, NRMSE Test/best: 1.13960/0.57585, Training NRMSE: 0.83006, deviation of 37.29%\n",
      "Epoch -17 calculated in 547.72 s \n",
      "Epoch 17, NRMSE Test/best: 1.24090/0.57585, Training NRMSE: 0.92219, deviation of 34.56%\n",
      "Epoch -18 calculated in 547.90 s \n",
      "Epoch 18, NRMSE Test/best: 1.03070/0.57585, Training NRMSE: 0.90910, deviation of 13.38%\n",
      "Epoch -19 calculated in 545.96 s \n",
      "Epoch 19, NRMSE Test/best: 1.31893/0.57585, Training NRMSE: 0.99728, deviation of 32.25%\n",
      "Epoch -20 calculated in 545.74 s \n",
      "Epoch 20, NRMSE Test/best: 1.10336/0.57585, Training NRMSE: 1.00206, deviation of 10.11%\n",
      "Epoch -21 calculated in 546.20 s \n",
      "Epoch 21, NRMSE Test/best: 1.09851/0.57585, Training NRMSE: 0.99137, deviation of 10.81%\n",
      "Epoch -22 calculated in 546.42 s \n",
      "Epoch 22, NRMSE Test/best: 1.24068/0.57585, Training NRMSE: 0.94909, deviation of 30.72%\n",
      "Epoch -23 calculated in 530.49 s \n",
      "Epoch 23, NRMSE Test/best: 1.19596/0.57585, Training NRMSE: 0.90686, deviation of 31.88%\n",
      "Epoch -24 calculated in 529.65 s \n",
      "Epoch 24, NRMSE Test/best: 1.08261/0.57585, Training NRMSE: 0.87657, deviation of 23.50%\n",
      "Epoch -25 calculated in 530.68 s \n",
      "Epoch 25, NRMSE Test/best: 1.25125/0.57585, Training NRMSE: 0.91677, deviation of 36.48%\n",
      "Epoch -26 calculated in 529.95 s \n",
      "Epoch 26, NRMSE Test/best: 1.01458/0.57585, Training NRMSE: 0.90737, deviation of 11.82%\n",
      "Epoch -27 calculated in 529.88 s \n",
      "Epoch 27, NRMSE Test/best: 1.01907/0.57585, Training NRMSE: 0.98856, deviation of 3.09%\n",
      "Epoch -28 calculated in 530.44 s \n",
      "Epoch 28, NRMSE Test/best: 1.11378/0.57585, Training NRMSE: 0.96009, deviation of 16.01%\n",
      "Epoch -29 calculated in 530.59 s \n",
      "Epoch 29, NRMSE Test/best: 1.21039/0.57585, Training NRMSE: 0.92770, deviation of 30.47%\n",
      "Epoch -30 calculated in 533.82 s \n",
      "Epoch 30, NRMSE Test/best: 1.20947/0.57585, Training NRMSE: 0.84786, deviation of 42.65%\n",
      "Epoch -31 calculated in 535.59 s \n",
      "Epoch 31, NRMSE Test/best: 1.03710/0.57585, Training NRMSE: 0.73877, deviation of 40.38%\n",
      "Epoch -32 calculated in 536.19 s \n",
      "Epoch 32, NRMSE Test/best: 1.10995/0.57585, Training NRMSE: 0.70901, deviation of 56.55%\n",
      "Epoch -33 calculated in 537.13 s \n",
      "Epoch 33, NRMSE Test/best: 1.16706/0.57585, Training NRMSE: 0.77799, deviation of 50.01%\n",
      "Epoch -34 calculated in 536.34 s \n",
      "Epoch 34, NRMSE Test/best: 1.20895/0.57585, Training NRMSE: 0.78315, deviation of 54.37%\n",
      "Epoch -35 calculated in 537.95 s \n",
      "Epoch 35, NRMSE Test/best: 1.28211/0.57585, Training NRMSE: 0.74609, deviation of 71.85%\n",
      "Epoch -36 calculated in 537.62 s \n",
      "Epoch 36, NRMSE Test/best: 1.39423/0.57585, Training NRMSE: 0.77159, deviation of 80.70%\n",
      "Epoch -37 calculated in 538.18 s \n",
      "Epoch 37, NRMSE Test/best: 1.29961/0.57585, Training NRMSE: 0.93836, deviation of 38.50%\n",
      "Epoch -38 calculated in 538.56 s \n",
      "Epoch 38, NRMSE Test/best: 1.10533/0.57585, Training NRMSE: 0.91524, deviation of 20.77%\n",
      "Epoch -39 calculated in 539.61 s \n",
      "Epoch 39, NRMSE Test/best: 1.06198/0.57585, Training NRMSE: 0.85927, deviation of 23.59%\n",
      "Epoch -40 calculated in 538.25 s \n",
      "Epoch 40, NRMSE Test/best: 0.98926/0.57585, Training NRMSE: 0.94637, deviation of 4.53%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-39cd3a97f5e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpMSETrainTemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpEnergyTargetTemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEnergyTarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mpMSETrain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpMSETrainTemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mpEnergyTarget\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpEnergyTargetTemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"lstm for guitar signal\"\"\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('Codes')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from dataShaping import *\n",
    "from savePerf import *\n",
    "import scipy.io.wavfile\n",
    "import time\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.contrib.rnn import *\n",
    "from saveTransformedGraph import optimizeGraph\n",
    "\n",
    "modelName = \"LSTM_model2\"\n",
    "\n",
    "#############################\n",
    "# Directory experiment\n",
    "#############################\n",
    "date = time.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "path = os.path.join(\"Experiments\",date)\n",
    "if not os.path.isdir(path):\n",
    "    os.makedirs(path)\n",
    "    #experiment/\"date\"/temp will contain the backuped model parameters\n",
    "    pathTemp = os.path.join(path,'temp')\n",
    "    os.makedirs(pathTemp)\n",
    "    # if you run the file two time in a minute\n",
    "else :\n",
    "    date = date+'(2)'\n",
    "    path = os.path.join(\"Experiments\",date)\n",
    "    os.makedirs(path)\n",
    "    pathTemp = os.path.join(path,'temp')\n",
    "    os.makedirs(pathTemp)\n",
    "\n",
    "# directory that will contain tensorboard information\n",
    "pathLog = 'Tf_logs'\n",
    "if not os.path.isdir(pathLog):\n",
    "    os.makedirs(pathLog)\n",
    "pathLog = \"{}/run-{}/\".format(pathLog,date)\n",
    "\n",
    "version = tf.__version__\n",
    "print (\"version {} of tensorflow\".format(version))\n",
    "\n",
    "#############################\n",
    "# Model parameters\n",
    "#############################\n",
    "trainTestRatio = 0.8\n",
    "maxSize = 0\n",
    "num_step = 100\n",
    "num_hidden = 150\n",
    "num_out = 1\n",
    "num_feature = 1\n",
    "batch_size = 1000\n",
    "num_epoch = 10000                                      \n",
    "trainDuration = 60*60*15                             \n",
    "                                      \n",
    "amplifierName = 'EnglDisto'\n",
    "fileNameTrain = 'Datasets/training'+amplifierName+'.mat' # dataset train/test path\n",
    "fileNameTest = 'Datasets/test'+amplifierName+'.mat'      # dataset validation path\n",
    "fileNameValidation = 'Datasets/val'+amplifierName+'.mat'\n",
    "\n",
    "#############################\n",
    "# Loading data\n",
    "#############################\n",
    "matrix = sio.loadmat(fileNameTrain)\n",
    "matrixTrain = matrix['train']\n",
    "matrix = sio.loadmat(fileNameTest)\n",
    "matrixTest = matrix['test']\n",
    "if maxSize ==0:\n",
    "    maxSize = len(matrixTrain)\n",
    "    print(\"maxSize = {}\".format(maxSize))\n",
    "\n",
    "train_input,train_output,test_input,test_output = loadInputOutputSeq(matrixTrain,matrixTest,num_step,maxSize)\n",
    "print(\"shape input train {}\".format(np.shape(train_input)))\n",
    "numTrain = len(train_output)\n",
    "print (\"Data loaded\")\n",
    "\n",
    "#######################\n",
    "# Graph Construction\n",
    "#######################\n",
    "G = tf.Graph()\n",
    "with G.as_default():\n",
    "    with tf.name_scope(\"placeHolder\"):\n",
    "        data = tf.placeholder(tf.float32, [None, num_step], name =\"data\") \n",
    "        target = tf.placeholder(tf.float32, [None, num_out],name = \"target\") \n",
    "        dataShaped = tf.reshape(data,[tf.shape(data)[0],tf.shape(data)[1],num_feature])\n",
    "        dataShaped = tf.transpose(dataShaped,[1,0,2])\n",
    "    \n",
    "    with tf.name_scope(\"LSTMLayer1\"):\n",
    "        fusedCell1 = tf.contrib.rnn.LSTMBlockFusedCell(num_hidden,use_peephole=False)\n",
    "        val, state = fusedCell1(dataShaped,dtype=tf.float32) \n",
    "    with tf.name_scope(\"LSTMLayer2\"):\n",
    "        fusedCell2 = tf.contrib.rnn.LSTMBlockFusedCell(num_hidden,use_peephole=False)\n",
    "        val2, state2 = fusedCell2(val,dtype=tf.float32)       \n",
    "    with tf.name_scope(\"extractLastCelloftheLSTMLayer\"):\n",
    "        last_index = tf.shape(val2)[0] - 1\n",
    "        lastState = tf.gather(val2,last_index)\n",
    "    \n",
    "    prediction = fully_connected(lastState,int(target.get_shape()[1]),activation_fn=tf.nn.tanh,weights_regularizer=None,scope=\"FCPred\")\n",
    "    \n",
    "##############################\n",
    "# Cost function\n",
    "##############################\n",
    "    MSE = tf.reduce_mean(tf.square(prediction-target))\n",
    "    EnergyTarget = tf.reduce_mean(tf.square(target)) \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    minimize = optimizer.minimize(MSE)\n",
    "    # Create summary view for tensorboard\n",
    "    mse_summary = tf.summary.scalar('RMSE',tf.sqrt(MSE))\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    #Create an init op to initialize variable\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver() \n",
    "##############################\n",
    "# Graph execution\n",
    "##############################\n",
    "    \n",
    "with tf.Session(graph=G) as sess:\n",
    "    #restorePath = os.path.join('2017-09-11-18-07','temp','my_model.ckpt')\n",
    "    #saver.restore(sess,restorePath)\n",
    "    sess.run(init_op)\n",
    "    train_writer = tf.summary.FileWriter(pathLog+'train',graph =tf.get_default_graph())\n",
    "    test_writer = tf.summary.FileWriter(pathLog+'test')\n",
    "    \n",
    "    no_of_batches = int(np.floor((numTrain)/batch_size)) # numtrain -numstep    no_of_batchesTest = int(np.floor((len(test_input)-num_step)/batch_size))\n",
    "    no_of_batchesTest = int(np.floor((len(test_input))/batch_size))\n",
    "    tStart = time.clock()\n",
    "    epoch =0\n",
    "    NRMSETest = 1\n",
    "    bestNRMSETest = 1    \n",
    "    # train until the number of epochs or the training time is reached\n",
    "    for epoch in range(num_epoch):\n",
    "        tEpoch = time.clock()\n",
    "        if (time.clock()-tStart < trainDuration) :\n",
    "            ptr = 0\n",
    "            if epoch % 20==0 : # each twenty epochs, save the model\n",
    "                tf.train.write_graph(sess.graph_def,\"{}/\".format(pathTemp),'myGraph.pb',as_text=False)\n",
    "                save_path = saver.save(sess,os.path.join(pathTemp,'myModel.ckpt'))\n",
    "            \n",
    "            pMSETrain=0\n",
    "            pEnergyTarget=0\n",
    "            for j in range(no_of_batches):\n",
    "                inp, out = train_input[ptr:ptr+batch_size],train_output[ptr:ptr+batch_size]\n",
    "                ptr+=batch_size\n",
    "                \n",
    "                if j % np.floor(numTrain/len(test_input)) ==0 : # This is to have a train summary and a test summary of the same size\n",
    "                    _,summary_str,pMSETrainTemp,pEnergyTargetTemp = sess.run([minimize,summary_op,MSE,EnergyTarget],{data: inp, target: out})\n",
    "                    pMSETrain += pMSETrainTemp\n",
    "                    pEnergyTarget += pEnergyTargetTemp\n",
    "                    step = epoch*no_of_batches+j\n",
    "                    # save the training RMSE for tensorboard\n",
    "                    train_writer.add_summary(summary_str,step)                   \n",
    "\n",
    "                else :\n",
    "                    _,pMSETrainTemp,pEnergyTargetTemp = sess.run([minimize,MSE,EnergyTarget],{data: inp, target: out})\n",
    "                    pMSETrain += pMSETrainTemp\n",
    "                    pEnergyTarget += pEnergyTargetTemp\n",
    "                    \n",
    "            # compute an estimation of the RMSE for this epoch       \n",
    "            MSETrain = pMSETrain/no_of_batches\n",
    "            EnergyTargetTrain = pEnergyTarget/no_of_batches\n",
    "            NRMSETrain = np.sqrt(MSETrain/EnergyTargetTrain)\n",
    "            print (\"Epoch -{} calculated in {:5.2f} s \".format(epoch,time.clock()-tEpoch))\n",
    "            # evaluate the model on the test set \n",
    "            pMSE = 0\n",
    "            ptr2 = 0\n",
    "            pEnergyTarget = 0\n",
    "            for k in range(no_of_batchesTest):\n",
    "                pMSETemp,pEnergyTargetTemp,summary_str = sess.run([MSE,EnergyTarget,summary_op],{data: test_input[ptr2:ptr2+batch_size] , target: test_output[ptr2:ptr2+batch_size]})\n",
    "                pMSE += pMSETemp\n",
    "                ptr2 += batch_size\n",
    "                pEnergyTarget+=pEnergyTargetTemp\n",
    "                step = epoch*no_of_batchesTest+k\n",
    "                test_writer.add_summary(summary_str,step*np.floor(numTrain/len(test_input)))\n",
    "            MSETest = pMSE/no_of_batchesTest\n",
    "            EnergyTargetTest = pEnergyTarget/no_of_batchesTest\n",
    "            NRMSETest = np.sqrt(MSETest/EnergyTargetTest)\n",
    "            if NRMSETest<bestNRMSETest:\n",
    "                bestNRMSETest=NRMSETest\n",
    "                tf.train.write_graph(sess.graph_def,\"{}/\".format(pathTemp),'myBestGraph.pbtxt',as_text=True)\n",
    "                save_path = saver.save(sess,os.path.join(pathTemp,'myBestModel.ckpt'))\n",
    "            print(\"Epoch {}, NRMSE Test/best: {:.5f}/{:.5f}, Training NRMSE: {:.5f}, deviation of {:.2f}%\".format(epoch,NRMSETest,bestNRMSETest,NRMSETrain,100*np.sqrt((NRMSETrain-NRMSETest)**2)/NRMSETrain))\n",
    "        else : break # break the while loop if number of epoch is reached\n",
    "    tStop = time.clock()\n",
    "    trainTime = time.strftime(\"%d:%H:%M:%S \", time.gmtime(tStop-tStart))\n",
    "    \n",
    "    ################################################################\n",
    "    # Save Graph variable and information about the running session\n",
    "    ################################################################\n",
    "    # save graph model\n",
    "    tf.train.write_graph(sess.graph_def,\"{}/\".format(pathTemp),'myFinalGraph.pbtxt',as_text=True)\n",
    "    # Save checkpoint variables\n",
    "    save_path = saver.save(sess,os.path.join(pathTemp,'myFinalModel.ckpt'))\n",
    "    print (\"Training duration {}\".format(trainTime))\n",
    "    totalParameters =np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()])\n",
    "    print(\"Number of training variable {}\".format(totalParameters))\n",
    "    # log\n",
    "    infoLog={}\n",
    "    infoLog[\"path\"] = path\n",
    "    infoLog[\"MSE\"] = bestNRMSETest\n",
    "    infoLog[\"num_step\"] = num_step\n",
    "    infoLog[\"num_hidden\"] = num_hidden\n",
    "    infoLog[\"num_epoch\"] = epoch\n",
    "    infoLog[\"batch_size\"] = batch_size\n",
    "    infoLog[\"maxSize\"] = maxSize\n",
    "    infoLog[\"duration\"] = trainTime\n",
    "    infoLog[\"totalParameters\"] = totalParameters\n",
    "    infoLog[\"version\"] = version\n",
    "    infoLog[\"n_layer\"] = 1\n",
    "    infoLog[\"trainDropout\"] = 0\n",
    "    infoLog[\"nameModel\"] = modelName\n",
    "    infoLog[\"conv_chan\"] = [0]\n",
    "    infoLog[\"strides\"] = 0\n",
    "    infoLog[\"conv_size\"] = 0\n",
    "    infoLog[\"amplifierName\"]=amplifierName\n",
    "    logPerf(infoLog)\n",
    "    input_nodes=[\"placeHolder/data\"]\n",
    "    output_nodes=[\"FCPred/Tanh\"]\n",
    "    optimizeGraph(pathTemp,input_nodes,output_nodes) \n",
    "    \n",
    "    ################################################\n",
    "    #   Validation\n",
    "    ################################################\n",
    "    restorePath = os.path.join(pathTemp,'myBestModel.ckpt') # example for restore a previous model\n",
    "    saver.restore(sess,restorePath)\n",
    "    matrixVal = sio.loadmat(fileNameValidation)\n",
    "    matrixVal = matrixVal['val']  \n",
    "    valSize = 0\n",
    "    if valSize == 0 :\n",
    "        valSize = len(matrixVal)\n",
    "    \n",
    "    val_input,val_output = loadValidationSeq(matrixVal,num_step,valSize)\n",
    "    lPrediction = []\n",
    "    lTarget = []\n",
    "    ptr3 = 0\n",
    "    no_of_batchesVal = int(np.floor((len(val_input))/batch_size))\n",
    "    for k in range(no_of_batchesVal):\n",
    "        pPrediction,pTarget = sess.run([prediction,target],{data: val_input[ptr3:ptr3+batch_size], target: val_output[ptr3:ptr3+batch_size]}) \n",
    "        lPrediction.append(pPrediction)\n",
    "        lTarget.append(pTarget)   \n",
    "        ptr3+=batch_size\n",
    "    \n",
    "    predictionArray = np.array(lPrediction,dtype=np.float32).ravel()\n",
    "    targetArray = np.array(lTarget,dtype=np.float32).ravel()\n",
    "    scipy.io.wavfile.write(os.path.join(path,'prediction.wav'),44100,predictionArray)\n",
    "    scipy.io.wavfile.write(os.path.join(path,'target.wav'),44100,targetArray)\n",
    "\n",
    "    # save emulation in a pickle format\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(predictionArray[6000+2*num_step:6700+2*num_step],label='prediction')\n",
    "    ax.plot(targetArray[6000+2*num_step:6700+2*num_step],label='target')\n",
    "    ax.legend()\n",
    "    plt.xlabel('sample n')\n",
    "    plt.ylabel('Amplitude y[n]')\n",
    "    nameFigEstimation = os.path.join(path,\"targetVsPrediction.pickle\")\n",
    "    pickle.dump(ax,open(nameFigEstimation, 'wb'))\n",
    "print (\"done, good job kids\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from show import *\n",
    "%matplotlib notebook\n",
    "showPickle(nameFigEstimation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
